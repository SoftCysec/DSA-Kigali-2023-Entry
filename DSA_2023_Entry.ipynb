{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "4UtMtUD19EEA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"DSA_2023_Entry.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B1DroRwx3ENZ"
   },
   "source": [
    "## DSA 2023 Summer School Admittance Check\n",
    "\n",
    "Thanks for your interest in attending DSA Kigali 2023. To attend the summer school you have to have some level of basic Python proficiency. Completing the following notebook should ensure you have the right kind of background to benefit maximally from the Summer School. See you in Kigali!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "id": "7Upwjh9U3ENa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run these once ... Just in case \n",
    "#!pip install nose \n",
    "#!pip install otter-grader\n",
    "import IPython\n",
    "from IPython import get_ipython\n",
    "# Import the good stuff\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from nose.tools import assert_equal\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ibmmx8r3ENc"
   },
   "source": [
    "**Question 1:** Write a Python function to return a tuple of primes and non primes given an integer input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "id": "CWjGPqaO3ENc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following are the prime and non prime numbers smaller than or equal to 30\n",
      "((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n"
     ]
    }
   ],
   "source": [
    "def sieve(num):\n",
    "    primes = []\n",
    "    non_primes = []\n",
    "    for i in range(2, num+1):\n",
    "        is_prime = True\n",
    "        for j in range(2, int(i**0.5)+1):\n",
    "            if i % j == 0:\n",
    "                is_prime = False\n",
    "                break\n",
    "        if is_prime:\n",
    "            primes.append(i)\n",
    "        else:\n",
    "            non_primes.append(i)\n",
    "    return (tuple(primes), tuple(non_primes))\n",
    "\n",
    "...\n",
    "num = 30\n",
    "print(\"Following are the prime and non prime numbers smaller than or equal to\", num)\n",
    "print(sieve(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "XPyHcNdb9EEb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntYqVxEQ3ENd"
   },
   "source": [
    "**Question 2:** Create a dictionary to store the type and number of unique characters in the paragraph provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "id": "LlZ8GC4J3ENe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'T': 3, 'h': 17, 'e': 89, ' ': 192, 'f': 26, 'o': 68, 'l': 35, 'w': 16, 'i': 60, 'n': 42, 'g': 14, 's': 57, 'a': 48, 'm': 20, 'p': 11, 't': 65, 'x': 3, 'I': 1, 'u': 26, 'd': 27, 'r': 45, 'c': 31, 'k': 9, 'y': 19, 'b': 11, '.': 12, ':': 2, '1': 11, '2': 10, '3': 13, '4': 5, '5': 3, '6': 3, '7': 10, '8': 3, '9': 2, 'S': 2, 'V': 1, '‚Äô': 3, '0': 22, ',': 7, '(': 3, ')': 3, 'q': 3, 'A': 2, 'v': 4, 'F': 1, '-': 4, '{': 2, '}': 2, 'O': 3, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '`': 2, '*': 4, '^': 4, '‚Äú': 1, '‚Äù': 1, '‚Äò': 1, 'E': 1, '/': 1, '\\\\': 1}\n"
     ]
    }
   ],
   "source": [
    "paragraph = \"The following is sample text I used to practice special characters using keybr.com: 112233445566778899 Saturn V rocket‚Äôs first stage carries 203,400 gallons (770,000 liters) of kerosene fuel and 318,000 gallons (1.2 million liters) of liquid oxygen needed for combustion. At liftoff, the stage‚Äôs five F-1 rocket engines ignite and produce 7.5 million pounds of thrust. To replace those goofy quantities with the far less retarded metric system (even though liters are considered part of the metric system they are the same as cubic deci-meters) you would say 770 cubic meters of kerosene {abbreviated as m3} and 1,204 m3 of liquid O2 [O2 is the symbol for oxygen]. We would also say it produced 33,600,000 newtons of force <abbreviated as N>. To add scientific notation {a way of writing numbers that allows you to write only as many digits `of specificity` as you would like} you can write 7.7 * 10 ^ 2 m3 of kerosene 1.204 * 10 ^ 3 m3 of O2 and 3.3 * 10 ^ 7 newtons. Another way to write scientific notation is to replace the ‚Äú* 10 ^‚Äù with ‚ÄòE‚Äô -/capital e\\-. So our numbers would look like:s\"\n",
    "\n",
    "# import the libraries\n",
    "from collections import Counter\n",
    "\n",
    "# count the number of occurrences of each character\n",
    "char_count = Counter(paragraph)\n",
    "\n",
    "# create a dictionary of character type and count\n",
    "dictionary = dict(char_count)\n",
    "\n",
    "...\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "HYHSTDbv9EE0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! ‚ú®</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylvPVW8m3ENe"
   },
   "source": [
    "**Question 3:** Extract the values from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "id": "I50ccd1SJMn4",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\']\n"
     ]
    }
   ],
   "source": [
    "keysList = list(dictionary.keys())\n",
    "...\n",
    "print (keysList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7wQ0LbNd9EE4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hucvAvprJMn5"
   },
   "source": [
    "**Question 4:** Extract the keys from the dictionary above into a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "id": "wLHoBNERJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "valuesList = list(dictionary.values())\n",
    "...\n",
    "print (valuesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "WH8SeNDp9EE9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9PpnMsGpJMn5"
   },
   "source": [
    "**Question 5:** Merge the two lists into a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "id": "UDWWh3vQJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n"
     ]
    }
   ],
   "source": [
    "keysListTuple = tuple(keysList)\n",
    "valuesListTuple = tuple(valuesList)\n",
    "\n",
    "final_tuple = (keysListTuple, valuesListTuple)\n",
    "\n",
    "...\n",
    "print(final_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "qMUU0pLA9EE_"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed! üåü</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kjXsJZkg9EFA"
   },
   "source": [
    "**Question 6:**  Write a function `greatest_common_divisor` that takes two inputs `a` and `b` and returns the greatest common divisor of the two numbers. E.g. input `(10, 15)` would return `5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "id": "31ROM2dc9EFA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "def greatest_common_divisor(a, b):\n",
    "    ...\n",
    "    while b != 0:\n",
    "        a, b = b, a % b\n",
    "    return a\n",
    "\n",
    "print(greatest_common_divisor(10,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "e9VeOp0J9EFB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6</pre></strong> passed! üçÄ</p>"
      ],
      "text/plain": [
       "q6 results: All test cases passed!"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWKblaMJ9EFB"
   },
   "source": [
    "**Question 7:**  Write a function `get_nearest_farthest` that takes in a point of interest (pt) and a list of points and returns the nearest point and the farthest point from the point of intest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "id": "qstxfHqY9EFB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_nearest_farthest(pt, ptlist):\n",
    "    ...\n",
    "    if not ptlist:\n",
    "        return None, None  # empty list\n",
    "\n",
    "    nearest_pt = ptlist[0]\n",
    "    farthest_pt = ptlist[0]\n",
    "    nearest_dist = math.dist(pt, nearest_pt)\n",
    "    farthest_dist = nearest_dist\n",
    "\n",
    "    for p in ptlist:\n",
    "        dist = math.dist(pt, p)\n",
    "        if dist < nearest_dist:\n",
    "            nearest_pt = p\n",
    "            nearest_dist = dist\n",
    "        elif dist > farthest_dist:\n",
    "            farthest_pt = p\n",
    "            farthest_dist = dist\n",
    "\n",
    "    return nearest_pt, farthest_pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "U4066cnc9EFC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed! üéâ</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrkIsy5T9EFD"
   },
   "source": [
    "**Question 8:**  Write a function `perfectly_divisible` to return a list of numbers between 0 and a number $N$ that are perfectly divisible by $q$ (with out leaving a remainder). <br>\n",
    "**Hint**: $N$ should also be inclusive in the numbers being considered. If N is negative use N == 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "id": "40GXPFsJ9EFD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perfectly_divisible(N, q):\n",
    "    ...\n",
    "    if N < 0:\n",
    "        N = 20\n",
    "    return [n for n in range(N+1) if n % q == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "JW1VMiMi9EFE"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q8</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q8 results: All test cases passed!"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9jMeeAP9EFE"
   },
   "source": [
    "**Question 9:**  Write a function `flatten_lists` that takes in a list of lists and outputs a sorted list of elements of sublists of the input list (confusing right?) <br>\n",
    "Example: given `flatten_lists([[2,13,44], [6,7]])` it should return `[2,6,7,13,44]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "id": "tJ64KsnP9EFF",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 6, 7, 13, 44]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def flatten_lists(superlist):\n",
    "    ...\n",
    "    flat_list = [elem for sublist in superlist for elem in sublist]\n",
    "    flat_list.sort()\n",
    "    return flat_list\n",
    "\n",
    "superlist = [[2,13,44], [6,7]]\n",
    "flatten_lists(superlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "93vfDA0a9EFF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q9</pre></strong> passed! üåà</p>"
      ],
      "text/plain": [
       "q9 results: All test cases passed!"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2r7_MlE09EFF"
   },
   "source": [
    "**The Extra Mile!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_egf664jJMn5"
   },
   "source": [
    "**Download the dataset \"Nakuru Sensor Data for February 2023 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/14165682-37dd-4f40-914e-eb24619e4ef8\"**\n",
    "\n",
    "Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "id": "r2lE0yrPJMn5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              timestamp   value_type  value\n",
      "0      2023-02-04T04:22:51.323124+00:00     humidity    100\n",
      "1      2023-02-04T04:22:51.323124+00:00  temperature     12\n",
      "2      2023-02-04T04:22:51.323125+00:00           P2     27\n",
      "3      2023-02-04T04:22:51.323125+00:00           P1     59\n",
      "4      2023-02-04T04:25:32.354784+00:00     humidity    100\n",
      "...                                 ...          ...    ...\n",
      "42985  2023-02-24T07:51:55.687329+00:00  temperature     27\n",
      "42986  2023-02-24T07:54:35.530536+00:00     humidity     59\n",
      "42987  2023-02-24T07:54:35.530536+00:00  temperature     27\n",
      "42988  2023-02-24T07:54:35.530545+00:00           P2      0\n",
      "42989  2023-02-24T07:54:35.530545+00:00           P1      0\n",
      "\n",
      "[42990 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "#Load the 'timestamp','value_type' and 'value' collumns into a pandas dataframe \n",
    "\n",
    "df = pd.read_csv('Nakuru_Sensor_Data_Feb_2023.csv',usecols=['timestamp','value_type','value'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Er6lemMeJMn5"
   },
   "source": [
    "**Question E1:** Create a new collumn 'timestamp_new' from 'timestamp' rounded off to the second "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "id": "sQq3JIaVJMn5",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sensor_id sensor_type  location    lat     lon  \\\n",
      "0            145       DHT22      3528 -0.286  36.067   \n",
      "1            145       DHT22      3528 -0.286  36.067   \n",
      "2            144      SDS011      3528 -0.286  36.067   \n",
      "3            144      SDS011      3528 -0.286  36.067   \n",
      "4            145       DHT22      3528 -0.286  36.067   \n",
      "...          ...         ...       ...    ...     ...   \n",
      "42985        145       DHT22      3528 -0.286  36.067   \n",
      "42986        145       DHT22      3528 -0.286  36.067   \n",
      "42987        145       DHT22      3528 -0.286  36.067   \n",
      "42988        144      SDS011      3528 -0.286  36.067   \n",
      "42989        144      SDS011      3528 -0.286  36.067   \n",
      "\n",
      "                  timestamp_new   value_type  value  \n",
      "0     2023-02-04 04:22:51+00:00     humidity    100  \n",
      "1     2023-02-04 04:22:51+00:00  temperature     12  \n",
      "2     2023-02-04 04:22:51+00:00           P2     27  \n",
      "3     2023-02-04 04:22:51+00:00           P1     59  \n",
      "4     2023-02-04 04:25:32+00:00     humidity    100  \n",
      "...                         ...          ...    ...  \n",
      "42985 2023-02-24 07:51:55+00:00  temperature     27  \n",
      "42986 2023-02-24 07:54:35+00:00     humidity     59  \n",
      "42987 2023-02-24 07:54:35+00:00  temperature     27  \n",
      "42988 2023-02-24 07:54:35+00:00           P2      0  \n",
      "42989 2023-02-24 07:54:35+00:00           P1      0  \n",
      "\n",
      "[42990 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Nakuru_Sensor_Data_Feb_2023.csv')\n",
    "\n",
    "# Rename the timestamp column\n",
    "df = df.rename(columns={'timestamp': 'timestamp_new'})\n",
    "\n",
    "# Convert the timestamp column to datetime format\n",
    "df['timestamp_new'] = pd.to_datetime(df['timestamp_new'], infer_datetime_format=True)\n",
    "\n",
    "# Round off the timestamp to the nearest second\n",
    "df['timestamp_new'] = df['timestamp_new'].dt.floor('s')\n",
    "...\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HM8DysCJMn6"
   },
   "source": [
    "**Question E2:** Split the dataframe based on the 'value_type' collumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "id": "z3NUYMOZJMn6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby('value_type')\n",
    "df_temperature = grouped.get_group('temperature')\n",
    "df_humidity = grouped.get_group('humidity')\n",
    "df_P1 = grouped.get_group('P1')\n",
    "df_P2 = grouped.get_group('P2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAEsAuUvJMn6"
   },
   "source": [
    "**Question E3:** Find the mean, mode and median of the humidity, temperature, P1 and P2 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "id": "14T6jzZ_JMn6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature\n",
      "Mean =  22.35287548855388 Median =  22.0 Standard Deviation =  7.218686624924896\n",
      "Humidity\n",
      "Mean =  64.31109249953471 Median =  61.0 Standard Deviation =  22.407697062564353\n",
      "P1\n",
      "Mean =  28.508605451669922 Median =  20.0 Standard Deviation =  33.691468361874755\n",
      "P2\n",
      "Mean =  11.30142338822216 Median =  8.0 Standard Deviation =  11.865466667566395\n"
     ]
    }
   ],
   "source": [
    "# Mean, median and standard deviation of temperature\n",
    "mu_temp = df_temperature['value'].mean()\n",
    "med_temp = df_temperature['value'].median()\n",
    "sd_temp = df_temperature['value'].std()\n",
    "\n",
    "print(\"Temperature\")\n",
    "print(\"Mean = \",mu_temp, \"Median = \", med_temp, \"Standard Deviation = \", sd_temp)\n",
    "\n",
    "# Mean, median and standard deviation of humidity\n",
    "mu_humidity = df_humidity['value'].mean()\n",
    "med_humidity = df_humidity['value'].median()\n",
    "sd_humidity = df_humidity['value'].std()\n",
    "\n",
    "\n",
    "print(\"Humidity\")\n",
    "print(\"Mean = \",mu_humidity, \"Median = \", med_humidity, \"Standard Deviation = \", sd_humidity)\n",
    "\n",
    "# Mean, median and standard deviation of P1\n",
    "mu_P1 = df_P1['value'].mean()\n",
    "med_P1 = df_P1['value'].median()\n",
    "sd_P1 = df_P1['value'].std()\n",
    "\n",
    "print(\"P1\")\n",
    "print(\"Mean = \",mu_P1, \"Median = \", med_P1, \"Standard Deviation = \", sd_P1)\n",
    "\n",
    "# Mean, median and standard deviation of P2\n",
    "mu_P2 = df_P2['value'].mean()\n",
    "med_P2 = df_P2['value'].median()\n",
    "sd_P2 = df_P2['value'].std()\n",
    "\n",
    "print(\"P2\")\n",
    "print(\"Mean = \",mu_P2, \"Median = \", med_P2, \"Standard Deviation = \", sd_P2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKWBykh-JMn6"
   },
   "source": [
    "**Question E4:** Merge the grouped dataframes into one dataframe and save it as newdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "id": "4mQSIPfhJMn6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       sensor_id_temperature sensor_type_temperature  location_temperature  \\\n",
      "0                        145                   DHT22                  3528   \n",
      "1                        145                   DHT22                  3528   \n",
      "2                        145                   DHT22                  3528   \n",
      "3                        145                   DHT22                  3528   \n",
      "4                        145                   DHT22                  3528   \n",
      "...                      ...                     ...                   ...   \n",
      "10741                    145                   DHT22                  3528   \n",
      "10742                    145                   DHT22                  3528   \n",
      "10743                    145                   DHT22                  3528   \n",
      "10744                    145                   DHT22                  3528   \n",
      "10745                    145                   DHT22                  3528   \n",
      "\n",
      "       lat_temperature  lon_temperature             timestamp_new  \\\n",
      "0               -0.286           36.067 2023-02-04 04:22:51+00:00   \n",
      "1               -0.286           36.067 2023-02-04 04:25:32+00:00   \n",
      "2               -0.286           36.067 2023-02-04 04:28:12+00:00   \n",
      "3               -0.286           36.067 2023-02-04 04:30:52+00:00   \n",
      "4               -0.286           36.067 2023-02-04 04:33:32+00:00   \n",
      "...                ...              ...                       ...   \n",
      "10741           -0.286           36.067 2023-02-24 07:43:55+00:00   \n",
      "10742           -0.286           36.067 2023-02-24 07:46:35+00:00   \n",
      "10743           -0.286           36.067 2023-02-24 07:49:15+00:00   \n",
      "10744           -0.286           36.067 2023-02-24 07:51:55+00:00   \n",
      "10745           -0.286           36.067 2023-02-24 07:54:35+00:00   \n",
      "\n",
      "      value_type_temperature  value_temperature  sensor_id_humidity  \\\n",
      "0                temperature                 12                 145   \n",
      "1                temperature                 11                 145   \n",
      "2                temperature                 12                 145   \n",
      "3                temperature                 12                 145   \n",
      "4                temperature                 12                 145   \n",
      "...                      ...                ...                 ...   \n",
      "10741            temperature                 26                 145   \n",
      "10742            temperature                 26                 145   \n",
      "10743            temperature                 26                 145   \n",
      "10744            temperature                 27                 145   \n",
      "10745            temperature                 27                 145   \n",
      "\n",
      "      sensor_type_humidity  ...  lon_P1  value_type_P1  value_P1 sensor_id_P2  \\\n",
      "0                    DHT22  ...  36.067             P1      59.0        144.0   \n",
      "1                    DHT22  ...  36.067             P1      51.0        144.0   \n",
      "2                    DHT22  ...  36.067             P1      56.0        144.0   \n",
      "3                    DHT22  ...  36.067             P1      56.0        144.0   \n",
      "4                    DHT22  ...  36.067             P1     117.0        144.0   \n",
      "...                    ...  ...     ...            ...       ...          ...   \n",
      "10741                DHT22  ...  36.067             P1       0.0        144.0   \n",
      "10742                DHT22  ...  36.067             P1       7.0        144.0   \n",
      "10743                DHT22  ...  36.067             P1       1.0        144.0   \n",
      "10744                DHT22  ...  36.067             P1       0.0        144.0   \n",
      "10745                DHT22  ...  36.067             P1       0.0        144.0   \n",
      "\n",
      "       sensor_type_P2  location_P2 lat_P2  lon_P2  value_type_P2  value_P2  \n",
      "0              SDS011       3528.0 -0.286  36.067             P2      27.0  \n",
      "1              SDS011       3528.0 -0.286  36.067             P2      27.0  \n",
      "2              SDS011       3528.0 -0.286  36.067             P2      23.0  \n",
      "3              SDS011       3528.0 -0.286  36.067             P2      25.0  \n",
      "4              SDS011       3528.0 -0.286  36.067             P2      31.0  \n",
      "...               ...          ...    ...     ...            ...       ...  \n",
      "10741          SDS011       3528.0 -0.286  36.067             P2       0.0  \n",
      "10742          SDS011       3528.0 -0.286  36.067             P2       7.0  \n",
      "10743          SDS011       3528.0 -0.286  36.067             P2       1.0  \n",
      "10744          SDS011       3528.0 -0.286  36.067             P2       0.0  \n",
      "10745          SDS011       3528.0 -0.286  36.067             P2       0.0  \n",
      "\n",
      "[10746 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df_merged = df_temperature.merge(df_humidity,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged = df_merged.merge(df_P1,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged = df_merged.merge(df_P2,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "\n",
    "print(df_merged)\n",
    "\n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged.to_csv(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNLVvAvbJMn6"
   },
   "source": [
    "**Question E5:** Open the new data file and select only 'timestamp_new','value_temperature','value_humidity','value_P1' and 'value_P2' collunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "id": "4fyxaLq2JMn6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_new</th>\n",
       "      <th>value_temperature</th>\n",
       "      <th>value_humidity</th>\n",
       "      <th>value_P1</th>\n",
       "      <th>value_P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-04 04:22:51+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-04 04:25:32+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-04 04:28:12+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-04 04:30:52+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-04 04:33:32+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>117.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>2023-02-24 07:43:55+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>2023-02-24 07:46:35+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10743</th>\n",
       "      <td>2023-02-24 07:49:15+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>2023-02-24 07:51:55+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>2023-02-24 07:54:35+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10746 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp_new  value_temperature  value_humidity  value_P1  \\\n",
       "0      2023-02-04 04:22:51+00:00                 12             100      59.0   \n",
       "1      2023-02-04 04:25:32+00:00                 11             100      51.0   \n",
       "2      2023-02-04 04:28:12+00:00                 12             100      56.0   \n",
       "3      2023-02-04 04:30:52+00:00                 12             100      56.0   \n",
       "4      2023-02-04 04:33:32+00:00                 12             100     117.0   \n",
       "...                          ...                ...             ...       ...   \n",
       "10741  2023-02-24 07:43:55+00:00                 26              60       0.0   \n",
       "10742  2023-02-24 07:46:35+00:00                 26              60       7.0   \n",
       "10743  2023-02-24 07:49:15+00:00                 26              59       1.0   \n",
       "10744  2023-02-24 07:51:55+00:00                 27              59       0.0   \n",
       "10745  2023-02-24 07:54:35+00:00                 27              59       0.0   \n",
       "\n",
       "       value_P2  \n",
       "0          27.0  \n",
       "1          27.0  \n",
       "2          23.0  \n",
       "3          25.0  \n",
       "4          31.0  \n",
       "...         ...  \n",
       "10741       0.0  \n",
       "10742       7.0  \n",
       "10743       1.0  \n",
       "10744       0.0  \n",
       "10745       0.0  \n",
       "\n",
       "[10746 rows x 5 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the new data file\n",
    "new_df = pd.read_csv('newdata.csv')\n",
    "\n",
    "# Select the required columns\n",
    "new_df = new_df[['timestamp_new', 'value_temperature', 'value_humidity', 'value_P1', 'value_P2']]\n",
    "\n",
    "new_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fh5va_ODJMn6"
   },
   "source": [
    "**Question E6:** Replace the missing values in collumns 'value_P1' and 'value_P2' with the mean of the same collumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "id": "RAm29MW0JMn7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_new</th>\n",
       "      <th>value_temperature</th>\n",
       "      <th>value_humidity</th>\n",
       "      <th>value_P1</th>\n",
       "      <th>value_P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-02-04 04:41:32+00:00</td>\n",
       "      <td>13</td>\n",
       "      <td>100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2023-02-04 06:28:18+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2023-02-04 06:33:39+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>81</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>2023-02-04 08:09:43+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2023-02-04 08:23:06+00:00</td>\n",
       "      <td>29</td>\n",
       "      <td>43</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10710</th>\n",
       "      <td>2023-02-24 06:21:11+00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10714</th>\n",
       "      <td>2023-02-24 06:31:51+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10716</th>\n",
       "      <td>2023-02-24 06:37:12+00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10727</th>\n",
       "      <td>2023-02-24 07:06:34+00:00</td>\n",
       "      <td>23</td>\n",
       "      <td>71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10734</th>\n",
       "      <td>2023-02-24 07:25:13+00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>691 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp_new  value_temperature  value_humidity  value_P1  \\\n",
       "7      2023-02-04 04:41:32+00:00                 13             100       NaN   \n",
       "47     2023-02-04 06:28:18+00:00                 20              83       NaN   \n",
       "49     2023-02-04 06:33:39+00:00                 21              81       NaN   \n",
       "85     2023-02-04 08:09:43+00:00                 27              46       NaN   \n",
       "90     2023-02-04 08:23:06+00:00                 29              43       NaN   \n",
       "...                          ...                ...             ...       ...   \n",
       "10710  2023-02-24 06:21:11+00:00                 20              84       NaN   \n",
       "10714  2023-02-24 06:31:51+00:00                 21              82       NaN   \n",
       "10716  2023-02-24 06:37:12+00:00                 21              76       NaN   \n",
       "10727  2023-02-24 07:06:34+00:00                 23              71       NaN   \n",
       "10734  2023-02-24 07:25:13+00:00                 25              68       NaN   \n",
       "\n",
       "       value_P2  \n",
       "7           NaN  \n",
       "47          NaN  \n",
       "49          NaN  \n",
       "85          NaN  \n",
       "90          NaN  \n",
       "...         ...  \n",
       "10710       NaN  \n",
       "10714       NaN  \n",
       "10716       NaN  \n",
       "10727       NaN  \n",
       "10734       NaN  \n",
       "\n",
       "[691 rows x 5 columns]"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check for missing values \n",
    "\n",
    "missing_values = pd.isnull(new_df['value_P1'])\n",
    "\n",
    "# displaying data only with NaN\n",
    "new_df[missing_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "id": "JJ2zFruYJMn7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_new</th>\n",
       "      <th>value_temperature</th>\n",
       "      <th>value_humidity</th>\n",
       "      <th>value_P1</th>\n",
       "      <th>value_P2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-02-04 04:22:51+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>59.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-02-04 04:25:32+00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>100</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-02-04 04:28:12+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-02-04 04:30:52+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>56.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-02-04 04:33:32+00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>100</td>\n",
       "      <td>117.0</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10741</th>\n",
       "      <td>2023-02-24 07:43:55+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10742</th>\n",
       "      <td>2023-02-24 07:46:35+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>60</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10743</th>\n",
       "      <td>2023-02-24 07:49:15+00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10744</th>\n",
       "      <td>2023-02-24 07:51:55+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10745</th>\n",
       "      <td>2023-02-24 07:54:35+00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10746 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   timestamp_new  value_temperature  value_humidity  value_P1  \\\n",
       "0      2023-02-04 04:22:51+00:00                 12             100      59.0   \n",
       "1      2023-02-04 04:25:32+00:00                 11             100      51.0   \n",
       "2      2023-02-04 04:28:12+00:00                 12             100      56.0   \n",
       "3      2023-02-04 04:30:52+00:00                 12             100      56.0   \n",
       "4      2023-02-04 04:33:32+00:00                 12             100     117.0   \n",
       "...                          ...                ...             ...       ...   \n",
       "10741  2023-02-24 07:43:55+00:00                 26              60       0.0   \n",
       "10742  2023-02-24 07:46:35+00:00                 26              60       7.0   \n",
       "10743  2023-02-24 07:49:15+00:00                 26              59       1.0   \n",
       "10744  2023-02-24 07:51:55+00:00                 27              59       0.0   \n",
       "10745  2023-02-24 07:54:35+00:00                 27              59       0.0   \n",
       "\n",
       "       value_P2  \n",
       "0          27.0  \n",
       "1          27.0  \n",
       "2          23.0  \n",
       "3          25.0  \n",
       "4          31.0  \n",
       "...         ...  \n",
       "10741       0.0  \n",
       "10742       7.0  \n",
       "10743       1.0  \n",
       "10744       0.0  \n",
       "10745       0.0  \n",
       "\n",
       "[10746 rows x 5 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(\"The mean of P1\",new_df['value_P2'].mean())\n",
    "#print(\"The mean of P2\",new_df['value_P1'].mean())\n",
    "\n",
    "#replace missing values with the mean \n",
    "# Calculate mean of value_P1 and value_P2\n",
    "mean_P1 = new_df['value_P1'].mean()\n",
    "mean_P2 = new_df['value_P2'].mean()\n",
    "\n",
    "# Replace missing values with the mean\n",
    "new_df['value_P1'].fillna(mean_P1, inplace=True)\n",
    "new_df['value_P2'].fillna(mean_P2, inplace=True)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "syjHmz-AJMn7"
   },
   "source": [
    "**Question E7:** Compute the correlations between temperature and humidity; P1 and P2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "id": "agvSVKsEJMn7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between temparature and humidity -0.9028239849182673\n",
      "Correlation between P1 and P2 0.8734801215476388\n"
     ]
    }
   ],
   "source": [
    "#Correlation between temperature and humidity\n",
    "corr_temp_hum = new_df['value_temperature'].corr(new_df['value_humidity'])\n",
    "\n",
    "print (\"Correlation between temparature and humidity\",corr_temp_hum)\n",
    "\n",
    "#Correlation between P1 and P2\n",
    "corr_p1_p2 = new_df['value_P1'].corr(new_df['value_P2'])\n",
    "\n",
    "print (\"Correlation between P1 and P2\",corr_p1_p2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIy00VyKJMn7"
   },
   "source": [
    "**Question E8:** Create a new dataframe comprising of the average values of the variables by day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "id": "qb_G74GPJMn7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_temperature</th>\n",
       "      <th>value_humidity</th>\n",
       "      <th>value_P1</th>\n",
       "      <th>value_P2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_new</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-04 00:00:00+00:00</th>\n",
       "      <td>22.312783</td>\n",
       "      <td>62.269231</td>\n",
       "      <td>22.261655</td>\n",
       "      <td>7.998801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-05 00:00:00+00:00</th>\n",
       "      <td>22.171759</td>\n",
       "      <td>68.225926</td>\n",
       "      <td>28.545665</td>\n",
       "      <td>12.723529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-06 00:00:00+00:00</th>\n",
       "      <td>22.223562</td>\n",
       "      <td>61.916048</td>\n",
       "      <td>35.875720</td>\n",
       "      <td>13.835411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-07 00:00:00+00:00</th>\n",
       "      <td>22.747227</td>\n",
       "      <td>65.021719</td>\n",
       "      <td>33.383922</td>\n",
       "      <td>13.310616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-08 00:00:00+00:00</th>\n",
       "      <td>22.932282</td>\n",
       "      <td>62.166976</td>\n",
       "      <td>26.097481</td>\n",
       "      <td>9.938813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-09 00:00:00+00:00</th>\n",
       "      <td>18.371345</td>\n",
       "      <td>74.260234</td>\n",
       "      <td>2.217649</td>\n",
       "      <td>0.977087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value_temperature  value_humidity   value_P1  \\\n",
       "timestamp_new                                                             \n",
       "2023-02-04 00:00:00+00:00          22.312783       62.269231  22.261655   \n",
       "2023-02-05 00:00:00+00:00          22.171759       68.225926  28.545665   \n",
       "2023-02-06 00:00:00+00:00          22.223562       61.916048  35.875720   \n",
       "2023-02-07 00:00:00+00:00          22.747227       65.021719  33.383922   \n",
       "2023-02-08 00:00:00+00:00          22.932282       62.166976  26.097481   \n",
       "2023-02-09 00:00:00+00:00          18.371345       74.260234   2.217649   \n",
       "\n",
       "                            value_P2  \n",
       "timestamp_new                         \n",
       "2023-02-04 00:00:00+00:00   7.998801  \n",
       "2023-02-05 00:00:00+00:00  12.723529  \n",
       "2023-02-06 00:00:00+00:00  13.835411  \n",
       "2023-02-07 00:00:00+00:00  13.310616  \n",
       "2023-02-08 00:00:00+00:00   9.938813  \n",
       "2023-02-09 00:00:00+00:00   0.977087  "
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['timestamp_new'] = pd.to_datetime(df['timestamp_new'], infer_datetime_format=True) \n",
    "new_df['timestamp_new'] = df['timestamp_new'].dt.floor('d')\n",
    "\n",
    "means_feb = new_df.groupby('timestamp_new').mean()\n",
    "means_feb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXrFVTUPJMn7"
   },
   "source": [
    "**Question E9:** Download the dataset \"Nakuru Sensor Data for November 2021 from https://open.africa/dataset/sensorsafrica-airquality-archive-nakuru/resource/1f11351e-156b-4e4c-a063-b86a6ee07c4a\"\n",
    "\n",
    "Load the data into a pandas dataframe and develop a dataframe similar to what you have just done in Question no's 6 - 13 above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "id": "ooqx8xuoJMn7",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value_temperature</th>\n",
       "      <th>value_humidity</th>\n",
       "      <th>value_P1</th>\n",
       "      <th>value_P2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_new</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-11-08 00:00:00+00:00</th>\n",
       "      <td>22.686364</td>\n",
       "      <td>58.345455</td>\n",
       "      <td>15.630461</td>\n",
       "      <td>7.453988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-09 00:00:00+00:00</th>\n",
       "      <td>20.658672</td>\n",
       "      <td>70.549815</td>\n",
       "      <td>17.660227</td>\n",
       "      <td>9.380498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-10 00:00:00+00:00</th>\n",
       "      <td>19.238722</td>\n",
       "      <td>76.812030</td>\n",
       "      <td>16.701885</td>\n",
       "      <td>9.655554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-11 00:00:00+00:00</th>\n",
       "      <td>18.610200</td>\n",
       "      <td>77.810565</td>\n",
       "      <td>22.339171</td>\n",
       "      <td>12.062515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-12 00:00:00+00:00</th>\n",
       "      <td>21.483636</td>\n",
       "      <td>62.605455</td>\n",
       "      <td>15.782991</td>\n",
       "      <td>8.350538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-13 00:00:00+00:00</th>\n",
       "      <td>20.445455</td>\n",
       "      <td>68.125455</td>\n",
       "      <td>15.699063</td>\n",
       "      <td>8.076514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-14 00:00:00+00:00</th>\n",
       "      <td>20.840445</td>\n",
       "      <td>65.487941</td>\n",
       "      <td>13.231398</td>\n",
       "      <td>7.141338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-15 00:00:00+00:00</th>\n",
       "      <td>19.716946</td>\n",
       "      <td>70.808194</td>\n",
       "      <td>16.817734</td>\n",
       "      <td>9.020470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-16 00:00:00+00:00</th>\n",
       "      <td>16.784672</td>\n",
       "      <td>87.235401</td>\n",
       "      <td>23.040520</td>\n",
       "      <td>13.219563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-17 00:00:00+00:00</th>\n",
       "      <td>20.812727</td>\n",
       "      <td>65.520000</td>\n",
       "      <td>20.094118</td>\n",
       "      <td>11.903355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-18 00:00:00+00:00</th>\n",
       "      <td>20.660036</td>\n",
       "      <td>64.589512</td>\n",
       "      <td>17.037333</td>\n",
       "      <td>8.820608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-19 00:00:00+00:00</th>\n",
       "      <td>19.675373</td>\n",
       "      <td>72.738806</td>\n",
       "      <td>23.953518</td>\n",
       "      <td>12.015432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-20 00:00:00+00:00</th>\n",
       "      <td>20.258590</td>\n",
       "      <td>73.309222</td>\n",
       "      <td>98.767968</td>\n",
       "      <td>63.060507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-21 00:00:00+00:00</th>\n",
       "      <td>19.734545</td>\n",
       "      <td>75.543636</td>\n",
       "      <td>18.985610</td>\n",
       "      <td>10.767766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-22 00:00:00+00:00</th>\n",
       "      <td>21.287273</td>\n",
       "      <td>59.676364</td>\n",
       "      <td>14.702265</td>\n",
       "      <td>7.723609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-23 00:00:00+00:00</th>\n",
       "      <td>17.869444</td>\n",
       "      <td>70.538889</td>\n",
       "      <td>21.311898</td>\n",
       "      <td>10.154738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24 00:00:00+00:00</th>\n",
       "      <td>20.692168</td>\n",
       "      <td>65.519126</td>\n",
       "      <td>23.472725</td>\n",
       "      <td>10.063291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25 00:00:00+00:00</th>\n",
       "      <td>18.238616</td>\n",
       "      <td>83.597450</td>\n",
       "      <td>24.031706</td>\n",
       "      <td>13.935697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-26 00:00:00+00:00</th>\n",
       "      <td>20.249091</td>\n",
       "      <td>79.381818</td>\n",
       "      <td>23.578989</td>\n",
       "      <td>14.231670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-27 00:00:00+00:00</th>\n",
       "      <td>20.527372</td>\n",
       "      <td>76.246350</td>\n",
       "      <td>18.454243</td>\n",
       "      <td>10.707223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-28 00:00:00+00:00</th>\n",
       "      <td>19.262774</td>\n",
       "      <td>87.664234</td>\n",
       "      <td>12.800815</td>\n",
       "      <td>7.363455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-29 00:00:00+00:00</th>\n",
       "      <td>19.217391</td>\n",
       "      <td>91.449275</td>\n",
       "      <td>14.431821</td>\n",
       "      <td>9.389554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-30 00:00:00+00:00</th>\n",
       "      <td>19.886861</td>\n",
       "      <td>79.702555</td>\n",
       "      <td>8.779496</td>\n",
       "      <td>4.687329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           value_temperature  value_humidity   value_P1  \\\n",
       "timestamp_new                                                             \n",
       "2021-11-08 00:00:00+00:00          22.686364       58.345455  15.630461   \n",
       "2021-11-09 00:00:00+00:00          20.658672       70.549815  17.660227   \n",
       "2021-11-10 00:00:00+00:00          19.238722       76.812030  16.701885   \n",
       "2021-11-11 00:00:00+00:00          18.610200       77.810565  22.339171   \n",
       "2021-11-12 00:00:00+00:00          21.483636       62.605455  15.782991   \n",
       "2021-11-13 00:00:00+00:00          20.445455       68.125455  15.699063   \n",
       "2021-11-14 00:00:00+00:00          20.840445       65.487941  13.231398   \n",
       "2021-11-15 00:00:00+00:00          19.716946       70.808194  16.817734   \n",
       "2021-11-16 00:00:00+00:00          16.784672       87.235401  23.040520   \n",
       "2021-11-17 00:00:00+00:00          20.812727       65.520000  20.094118   \n",
       "2021-11-18 00:00:00+00:00          20.660036       64.589512  17.037333   \n",
       "2021-11-19 00:00:00+00:00          19.675373       72.738806  23.953518   \n",
       "2021-11-20 00:00:00+00:00          20.258590       73.309222  98.767968   \n",
       "2021-11-21 00:00:00+00:00          19.734545       75.543636  18.985610   \n",
       "2021-11-22 00:00:00+00:00          21.287273       59.676364  14.702265   \n",
       "2021-11-23 00:00:00+00:00          17.869444       70.538889  21.311898   \n",
       "2021-11-24 00:00:00+00:00          20.692168       65.519126  23.472725   \n",
       "2021-11-25 00:00:00+00:00          18.238616       83.597450  24.031706   \n",
       "2021-11-26 00:00:00+00:00          20.249091       79.381818  23.578989   \n",
       "2021-11-27 00:00:00+00:00          20.527372       76.246350  18.454243   \n",
       "2021-11-28 00:00:00+00:00          19.262774       87.664234  12.800815   \n",
       "2021-11-29 00:00:00+00:00          19.217391       91.449275  14.431821   \n",
       "2021-11-30 00:00:00+00:00          19.886861       79.702555   8.779496   \n",
       "\n",
       "                            value_P2  \n",
       "timestamp_new                         \n",
       "2021-11-08 00:00:00+00:00   7.453988  \n",
       "2021-11-09 00:00:00+00:00   9.380498  \n",
       "2021-11-10 00:00:00+00:00   9.655554  \n",
       "2021-11-11 00:00:00+00:00  12.062515  \n",
       "2021-11-12 00:00:00+00:00   8.350538  \n",
       "2021-11-13 00:00:00+00:00   8.076514  \n",
       "2021-11-14 00:00:00+00:00   7.141338  \n",
       "2021-11-15 00:00:00+00:00   9.020470  \n",
       "2021-11-16 00:00:00+00:00  13.219563  \n",
       "2021-11-17 00:00:00+00:00  11.903355  \n",
       "2021-11-18 00:00:00+00:00   8.820608  \n",
       "2021-11-19 00:00:00+00:00  12.015432  \n",
       "2021-11-20 00:00:00+00:00  63.060507  \n",
       "2021-11-21 00:00:00+00:00  10.767766  \n",
       "2021-11-22 00:00:00+00:00   7.723609  \n",
       "2021-11-23 00:00:00+00:00  10.154738  \n",
       "2021-11-24 00:00:00+00:00  10.063291  \n",
       "2021-11-25 00:00:00+00:00  13.935697  \n",
       "2021-11-26 00:00:00+00:00  14.231670  \n",
       "2021-11-27 00:00:00+00:00  10.707223  \n",
       "2021-11-28 00:00:00+00:00   7.363455  \n",
       "2021-11-29 00:00:00+00:00   9.389554  \n",
       "2021-11-30 00:00:00+00:00   4.687329  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the dataset\n",
    "nov_df = pd.read_csv(r'november_2021_sensor_data_archive.csv',sep = ';') \n",
    "\n",
    "#creating a new column timestamp_new\n",
    "nov_df['timestamp'] = pd.to_datetime(nov_df['timestamp'], infer_datetime_format=True)\n",
    "nov_df['timestamp_new'] = nov_df['timestamp'].dt.floor('s')\n",
    "\n",
    "#grouping the data by value_type \n",
    "grouped_nov = nov_df.groupby(nov_df.value_type)\n",
    "df_temperature_nov = grouped_nov.get_group(\"temperature\")\n",
    "df_humidity_nov = grouped_nov.get_group(\"humidity\")\n",
    "df_P1_nov = grouped_nov.get_group(\"P1\")\n",
    "df_P2_nov= grouped_nov.get_group(\"P2\")\n",
    "\n",
    "\n",
    "#creating a new dataframe by merging the grouped data frames \n",
    "df_merged_nov = df_temperature_nov.merge(df_humidity_nov,how='left', on='timestamp_new',suffixes=('_temperature', '_humidity'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P1_nov,how='left', on='timestamp_new',suffixes=('_prev', '_P1'))\n",
    "df_merged_nov = df_merged_nov.merge(df_P2_nov,how='left', on='timestamp_new',suffixes=('_P1', '_P2'))\n",
    "\n",
    "#open the new file \n",
    "from pathlib import Path  \n",
    "filepath = Path('newdata_nov.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "df_merged_nov.to_csv(filepath)  \n",
    "\n",
    "new_nov_df = pd.read_csv(r'newdata_nov.csv',usecols=['timestamp_new','value_temperature','value_humidity','value_P1','value_P2'])\n",
    "#new_nov_df \n",
    "\n",
    "#replace missing values with the mean \n",
    "new_nov_df['value_P1'].fillna(new_nov_df['value_P1'].mean(), inplace=True) \n",
    "new_nov_df['value_P2'].fillna(new_nov_df['value_P2'].mean(), inplace=True) \n",
    "\n",
    "#Create a new dataframe comprising of the average values of the variables by day\n",
    "new_nov_df['timestamp_new'] = pd.to_datetime(new_nov_df['timestamp_new'], infer_datetime_format=True)\n",
    "new_nov_df['timestamp_new'] = new_nov_df['timestamp_new'].dt.floor('d')\n",
    "\n",
    "means_nov = new_nov_df.groupby('timestamp_new').mean()\n",
    "means_nov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS7RRkZpnYqa"
   },
   "source": [
    "**Question E10:** Convert the means_feb and means_nov to numpy arrays ... and then compute the average of each collumn\n",
    "\n",
    "Hint: The results are numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "id": "hbgK6RQ8nDXw",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.79315977, 65.64335563, 24.73034846,  9.79737637])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feb_array = means_feb.to_numpy()\n",
    "feb_avg = np.mean(feb_array, axis = 0)\n",
    "feb_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "id": "r6-iwnWSoIDE",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19.94945098, 73.18511072, 21.62199812, 12.1384875 ])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nov_array = means_nov.to_numpy() \n",
    "nov_avg = np.mean(nov_array, axis = 0)\n",
    "nov_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc6tiksMqSb0"
   },
   "source": [
    "**Question E11:** Write a function to compute the difference in the average temperature, humidity, P1 and P2 between November 2021 and February 2023\n",
    "\n",
    "Hint: The result is a vector of the form [w,x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "id": "AWCrhXpKqPJQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sub():\n",
    "    feb_array = means_feb.to_numpy()\n",
    "    nov_array = means_nov.to_numpy()\n",
    "    diff = np.mean(nov_array, axis=0) - np.mean(feb_array, axis=0)\n",
    "    return diff\n",
    " \n",
    "# Print the result of the subtraction\n",
    "difference = sub()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "AGbbIaLR9EFg"
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**\n",
    "\n",
    "Upload the generated zip file to the Google sheet please. Uploading work which is not yours will lead to non admittance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6GPTz5oF9EFi"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "nbconvert is required for Otter Export but it could not be found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[303], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Save your notebook first, then run this cell to export your submission.\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m grader\u001b[39m.\u001b[39;49mexport(run_tests\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/check/utils.py:156\u001b[0m, in \u001b[0;36mgrading_mode_disabled\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_grading_mode:\n\u001b[1;32m    155\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/check/utils.py:143\u001b[0m, in \u001b[0;36mincompatible_with.<locals>.incompatible\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    142\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/check/utils.py:193\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    192\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_event(event_type, success\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, error\u001b[39m=\u001b[39me)\n\u001b[0;32m--> 193\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    195\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    196\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_event(event_type, results\u001b[39m=\u001b[39mresults, question\u001b[39m=\u001b[39mquestion, shelve_env\u001b[39m=\u001b[39mshelve_env)\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/check/utils.py:187\u001b[0m, in \u001b[0;36mlogs_event.<locals>.event_logger\u001b[0;34m(wrapped, self, args, kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m     question, results, shelve_env \u001b[39m=\u001b[39m wrapped(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    186\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     results \u001b[39m=\u001b[39m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    188\u001b[0m     shelve_env \u001b[39m=\u001b[39m {}\n\u001b[1;32m    189\u001b[0m     question \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/check/notebook.py:380\u001b[0m, in \u001b[0;36mNotebook.export\u001b[0;34m(self, nb_path, export_path, pdf, filtering, pagebreaks, files, display_link, force_save, run_tests)\u001b[0m\n\u001b[1;32m    377\u001b[0m zf\u001b[39m.\u001b[39mwrite(nb_path)\n\u001b[1;32m    379\u001b[0m \u001b[39mif\u001b[39;00m pdf:\n\u001b[0;32m--> 380\u001b[0m     pdf_path \u001b[39m=\u001b[39m export_notebook(nb_path, filtering\u001b[39m=\u001b[39;49mfiltering, pagebreaks\u001b[39m=\u001b[39;49mpagebreaks)\n\u001b[1;32m    381\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(pdf_path):\n\u001b[1;32m    382\u001b[0m         zf\u001b[39m.\u001b[39mwrite(pdf_path)\n",
      "File \u001b[0;32m~/Desktop/DSA_2023_Kigali/DSA/lib/python3.10/site-packages/otter/export/__init__.py:32\u001b[0m, in \u001b[0;36mexport_notebook\u001b[0;34m(nb_path, dest, exporter_type, **kwargs)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mExports a notebook file at ``nb_path`` to a PDF with optional filtering and pagebreaks. Accepts\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39mother ``kwargs`` passed to the exporter class's ``convert_notebook`` class method.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m    ``str``: the path at which the PDF was written\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m _MISSING_NBCONVERT:\n\u001b[0;32m---> 32\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mnbconvert is required for Otter Export but it could not be found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mexporters\u001b[39;00m \u001b[39mimport\u001b[39;00m get_exporter\n\u001b[1;32m     36\u001b[0m \u001b[39mif\u001b[39;00m dest \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: nbconvert is required for Otter Export but it could not be found"
     ]
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(run_tests=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZXba7mz69EFj"
   },
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": 2,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_primes(sieve):\n...     assert sieve(30) == ((2, 3, 5, 7, 11, 13, 17, 19, 23, 29), (4, 6, 8, 9, 10, 12, 14, 15, 16, 18, 20, 21, 22, 24, 25, 26, 27, 28, 30))\n>>> test_primes(sieve)  \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_dictionary(Counter):\n...     assert Counter(paragraph) == {' ': 192, 'e': 89, 'o': 68, 't': 65, 'i': 60, 's': 57, 'a': 48, 'r': 45, 'n': 42, 'l': 35, 'c': 31, 'd': 27, 'f': 26, 'u': 26, '0': 22, 'm': 20, 'y': 19, 'h': 17, 'w': 16, 'g': 14, '3': 13, '.': 12, 'p': 11, 'b': 11, '1': 11, '2': 10, '7': 10, 'k': 9, ',': 7, '4': 5, 'v': 4, '-': 4, '*': 4, '^': 4, 'T': 3, 'x': 3, '5': 3, '6': 3, '8': 3, '‚Äô': 3, '(': 3, ')': 3, 'q': 3, 'O': 3, ':': 2, '9': 2, 'S': 2, 'A': 2, '{': 2, '}': 2, '`': 2, 'I': 1, 'V': 1, 'F': 1, '[': 1, ']': 1, 'W': 1, '<': 1, 'N': 1, '>': 1, '‚Äú': 1, '‚Äù': 1, '‚Äò': 1, 'E': 1, '/': 1, '\\\\': 1}\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_keyslist():\n...     assert list(dictionary.keys()) == ['T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\']\n>>> test_keyslist() \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_valueslist():\n...     assert list(dictionary.values()) == [3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1]\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> # BEGIN TEST CONFIG\n>>> points: 2\n>>> # END TEST CONFIG\n>>> def test_tuple():\n...     assert final_tuple == (('T', 'h', 'e', ' ', 'f', 'o', 'l', 'w', 'i', 'n', 'g', 's', 'a', 'm', 'p', 't', 'x', 'I', 'u', 'd', 'r', 'c', 'k', 'y', 'b', '.', ':', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'S', 'V', '‚Äô', '0', ',', '(', ')', 'q', 'A', 'v', 'F', '-', '{', '}', 'O', '[', ']', 'W', '<', 'N', '>', '`', '*', '^', '‚Äú', '‚Äù', '‚Äò', 'E', '/', '\\\\'), (3, 17, 89, 192, 26, 68, 35, 16, 60, 42, 14, 57, 48, 20, 11, 65, 3, 1, 26, 27, 45, 31, 9, 19, 11, 12, 2, 11, 10, 13, 5, 3, 3, 10, 3, 2, 2, 1, 3, 22, 7, 3, 3, 3, 2, 4, 1, 4, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 4, 4, 1, 1, 1, 1, 1, 1))\n>>> test_tuple() \n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(greatest_common_divisor(10, 15), 5)\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(get_nearest_farthest((3, 8), [(9, 3), (8,5), (7,6)]), ((7, 6), (9, 3)))\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(perfectly_divisible(10,2), [0,2,4,6,8,10])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert_equal(flatten_lists([[2,13,44], [6,7]]), [2, 6, 7, 13, 44])\n",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
